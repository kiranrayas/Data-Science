{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8b228382",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Kiran Rao"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7b778f06",
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing pandas\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "621a5150",
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating df1, df2 and df_empty dataframes which can be globally accessible\n",
    "df1 = pd.DataFrame()\n",
    "df2 = pd.DataFrame()\n",
    "df_empty = pd.DataFrame()\n",
    "\n",
    "#function process_articles takes one argument: filename\n",
    "def process_articles(filename):\n",
    "    ##2 use read_csv() to read file\n",
    "    global df1\n",
    "    df1 = pd.read_csv(filename, delimiter = ',', header = 0, encoding_errors = 'ignore')\n",
    "\n",
    "    \n",
    "    ##3 use pandas for processing\n",
    "    #1 assign numerical identifiers and store it in a new column ID\n",
    "    #a new cloumn 'ID' is created maintaining the order of the rows by using the function reset_index()\n",
    "    df1['ID'] = df1.reset_index().index\n",
    "    \n",
    "    \n",
    "    #2 convert all numeric values to integer\n",
    "    #All publication Year values are converted to int if numeric and -9999 if non-numeric\n",
    "    #Here it first checks if the value is null, if true, 0 is assigned\n",
    "    #Then it checks if the value is an interger, if true it keeps it as it is\n",
    "    #it then checks if the value contains a decimal point, if true, the value before the decimal point is kept\n",
    "    #it checks if the string value is numeric, if true it converts to int\n",
    "    #else if the value is non numeric, it assigns -9999\n",
    "    df1['Publication Year'] = df1['Publication Year'].apply(lambda x: 0 if pd.isnull(x) else (x if isinstance(x, int) == True else(int(x.split('.')[0]) if '.' in x else (int(x) if x.isnumeric() else -9999))))\n",
    "    \n",
    "    #3 replace no author by an empty string\n",
    "    #Here it first extracts the 'Authors' that has 'no authors' value into a series s\n",
    "    #replaces such fields by an empty string\n",
    "    #counts the number of such fields and stores it in c_auth\n",
    "    s = df1[df1['Authors'] == 'no author']['Authors']\n",
    "    df1.loc[s.index, 'Authors'] = \"\"\n",
    "    c_auth = len(s)\n",
    "\n",
    "    #4 represent missing entry in abstract by an empty string\n",
    "    #counts the number of fields with an empty string for 'Abstract' and stores it in c_abst\n",
    "    #replaces such fields with an empty string\n",
    "    c_abst = df1['Abstract'].isna().sum()\n",
    "    df1.loc[df1['Abstract'].isnull(), 'Abstract'] = \"\"\n",
    "    \n",
    "    #5 count the number of empty DOIs\n",
    "    #counts the number of fields with an empty 'DOI' and stores it in c_doi\n",
    "    #also checks if there are any empty DOIs, if present, it proceeds to match the DOIs\n",
    "    c_doi = df1['DOI'].isna().sum()\n",
    "    c_match_doi = 0\n",
    "    if c_doi>0:\n",
    "        #5a replace empty DOIs by an empty string\n",
    "        #replaces empty fields with an empty string\n",
    "        df1.loc[df1['DOI'].isnull(), 'DOI'] = \"\"\n",
    "        \n",
    "        #checks if there are any Unnamed columns. If present, it drops them\n",
    "        df1 = df1.loc[:,~df1.columns.str.contains('^Unnamed')]\n",
    "\n",
    "        #5b partition the dataframes: df_empty and df2\n",
    "        #creates two dataframes df_empty with all the rows that do not have a DOI and df2 with the rows that contains a DOI\n",
    "        global df_empty\n",
    "        global df2\n",
    "        df_empty = df1[df1['DOI'] == \"\"]\n",
    "        df2 = df1[df1['DOI']!= \"\"]\n",
    "        \n",
    "        #checks if the length of df2 and df_empty combined matches the length of df1\n",
    "        assert len(df1)==len(df_empty)+len(df2), 'DF PARTITION ERROR'\n",
    "        \n",
    "        #resets the indexes of df_empty and df2 to continuous index\n",
    "        df_empty = df_empty.reset_index(drop=True)\n",
    "        df2 = df2.reset_index(drop=True)\n",
    "        \n",
    "        #5c DOI match\n",
    "        #to match the DOI 2 new dataframes df_match_empty and df_match_d2 are created\n",
    "        #Document Title and DOI values are extracted from the dataframes df_empty and df2 respectively into df_match_empty and df_match_df2\n",
    "        df_match_empty = df_empty[['Document Title', 'DOI']]\n",
    "        df_match_df2 = df2[['Document Title', 'DOI']]\n",
    "        \n",
    "        #DOI is matched from df_match_empty and df_match_df2 using the merge function and is stores in m\n",
    "        #the column with the matched DOI is renamed as Possible DOI\n",
    "        m = pd.merge(df_match_empty, df_match_df2, how = 'left', on = 'Document Title')\n",
    "        m = m.rename(columns = {'DOI_y': 'Possible DOI'})\n",
    "        \n",
    "        #number of matched DOIs are counted and is stored in c_match_doi\n",
    "        c_match_doi = len(m.dropna())\n",
    "        \n",
    "        #the Possible DOI column from m is concatenated with columns in df_empty\n",
    "        df_empty = pd.concat([df_empty, m['Possible DOI']], axis = 1)\n",
    "\n",
    "        #Here df2 dataframe is merged with df_empty to combine everything back to one single dataframe\n",
    "        #To bring it back to the original form, the values are sorted using the column ID\n",
    "        #To make the Possible DOI column uniform, all the empty values are replaced by an empty string \n",
    "        final_df = df2.merge(df_empty, how = 'outer')\n",
    "        final_df = final_df.sort_values(by = 'ID')\n",
    "        final_df.loc[final_df['Possible DOI'].isnull(), 'Possible DOI'] = \"\"\n",
    "        \n",
    "        #uncomment this to view the final result\n",
    "#         print(final_df)\n",
    "\n",
    "    #did not replace the rest of the columns with empty values by an empty string as it was not asked\n",
    "        \n",
    "    #6 print message\n",
    "    print(\"Number missing: Authors = \", c_auth, \"; Abstracts = \", c_abst,\"; DOIs = \", c_doi, \"; Number of DOIs matched = \", c_match_doi)\n",
    "    \n",
    "    #was not sure if we had to return the values as it was not mentioned\n",
    "#     return df1, df_empty, df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6eca7a51",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number missing: Authors =  10 ; Abstracts =  8 ; DOIs =  16 ; Number of DOIs matched =  2\n"
     ]
    }
   ],
   "source": [
    "##1 execute the function process_articles(filename), filename being a csv file\n",
    "process_articles(\"research1.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a8a4817",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "622624f8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
